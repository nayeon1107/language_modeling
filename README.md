# Language Modeling

## 📚 파일 구조
```bash
📂 generated
 ┃ ┗ 📜 shakespeare_by_LSTM_T=0.1.txt
 ┃ ┗ 📜 shakespeare_by_LSTM_T=0.3.txt
 ┃ ┗ 📜 ...
 ┃ ┗ 📜 shakespeare_by_RNN_T=10.txt
📂 models
 ┃ ┗ 📜 best_state_LSTM_epoch97.pth
 ┃ ┗ 📜 best_state_RNN_epoch99.pth
 ┣ 📜 dataset.py
 ┣ 📜 generate.py
 ┣ 📜 main.py
 ┗ 📜 model.py
```

## 📃 Data
 **Shakespeare Dataset**



```bash
# shakespeare_train.txt

First Citizen:
Before we proceed any further, hear me speak.

All:
Speak, speak.

First Citizen:
You are all resolved rather to die than to famish?
```

---

## 🔗 Models 
- Vanila RNN
- LSTM

### Parameters
- embedding_dim = 128
- hidden_dim = 128
- n_layers = 1
&nbsp; &nbsp;


## 📊 Compare Result
### 🔍 Compare RNN & LSTM
![trainvalidloss](https://github.com/nayeon1107/language_modeling/assets/88521667/e0045051-30af-48c8-b3a3-3a487a43e23a)
```bash
▶ Train, Valid 모두 LSTM 이 Vanila RNN 보다 낮은 loss를 보임
```
&nbsp; &nbsp;
### 🔍 Compare Softmax Temperature T

**Generated by RNN (T=0.1)**
```bash
QUEEN ELIZABETH:
The common of the common me to the state to the state to the state to the people to the consul to the country to the seal the people to the consul to the people ...
```
**Generated by RNN (T=1)**
```
QUEEN ELIZABETH:
For the wherefore
Epond, watetith,
Withmaling
As to hain the nois o' the faults
Had, treague not? tell thee not again,
I am think'sh all ...
```
**Generated by RNN (T=10)**
```
QUEEN ELIZABETH:'n
nkmeg!
CT!m!-psprixpp:NWHam;:-rthyiyot?!!t'rme:, Yry-k,-:cl,aad,
lvy,!s.-peg-Immw'W!;'zps Sy!.:!-g':I!Im
ghipafwje qumbs.
!u AIIfttyss. J!:
Ak,fo-yeisessr?. ...
```

**Generated by LSTM (T=0.1)**
```bash
QUEEN ELIZABETH:
Come, come, come, come, my lord, as thou shalt not speak of the people, my lord, as they are they are they ...
```
**Generated by RNN (T=1)**
```
QUEEN ELIZABETH:
The state of Lancaster.
What dog you?

Volsce:
An in that is foe to the people,
As he say she that shall prove a bath. ...
```
**Generated by RNN (T=10)**
```
QUEEN ELIZABETH:: 'Nuruh'dH
mEDN
Va,. Lits?
RRAUTEuu!-wOl.i-Crnasl'ds';:fa'dweCt! UVYRiImcugewE!Wtse? we.!! ...
```

▶ T 가 낮은 값을 가질수록 비교적 일관되고 동일한 출력을 생성하는 모습을 확인할 수 있음

▶ T 가 높은 값을 가질수록 굉장히 다양한 출력을 생성하는 모습을 확인할 수 있음

![temperature](https://github.com/nayeon1107/language_modeling/assets/88521667/316631a0-101f-47f0-a65c-bb4ef7b7fe49)

▶ 다음 그림과 같이 T 값이 낮으면 클래스 간 확률 차이가 뚜렷해지며, 높아질수록 클래스 간 확률 분포를 평탄하게 함

▶ 너무 일관된 출력과 너무 다양한 출력 값 사이 적당한 T 값 지정 필요

---

패키지 다운로드
```python
pip install requirements.txt
```

모델 실행
```python
python main.py {model_to_use} # RNN, LSTM
```
